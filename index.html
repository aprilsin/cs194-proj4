<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="mystyle.css" />
  <title>
    CS194 Project 4: Facial Keypoint Detection with Neural Networks
  </title>
</head>

<body>
  <header text-align="right"> Fall 2020</header>
  <h1>CS194 Project 4: Facial Keypoint Detection with Neural Networks</h1>

  <h2>April Sin</h2>

  <h3>Overview</h3>
  <p>
    In the last project - Project 3: Face Morphing, we had to manually click the keypoints to identify a face.
    To step up our game, we are making this project that automatically detect the face for us! How we acheive this is
    by using convolutional neural networks.
  </p>


  <h3>Part 1: Nose Tip Detection</h3>
  <h4>Dataset and Dataloader</h4>
  <p>
    Before detecting the whole face, we will try detecting just the nose.
    We will be using the <a href=http://www2.imm.dtu.dk/~aam/datasets/datasets.html>IMM Face Dataset</a>. <br>All the
    images
    are resized to 240 x 320 and no data augmentations are done.
  </p>
  <p>For the dataloader, I used <code>batch_size = 64</code>.</p>

  <p>Here are some sampled images and the truth nose keypoint:</p>
  <div class="row">
    <div class="column_4">
      <img src="output/p1_d1.png" alt="Sample 1" />
    </div>
    <div class="column_4">
      <img src="output/p1_d2.png" alt="Sample 2" />
    </div>
    <div class="column_4">
      <img src="output/p1_d3.png" alt="Sample 3" />
    </div>
  </div>

  <h4>CNN Model</h4>
  <p> I used a neural network with 5 convolution layers, each followed by ReLU and max pooling. They are then followed
    by two fully connected layres. I used
    <code>kernel_size = (3, 3)</code> for all the layers that needed one.</p>
  <p>Here are all the conv layers:</p>
  <ol>
    <li>C1 = Conv2d(1, 24, 3)</li>
    <li>C2 = Conv2d(24, 30, 3</li>
    <li>C3 = Conv2d(30, 20, 3)</li>
    <li>FC1 = Linear(20 * 7 * 10, 128)</li>
    <li>FC2 = Linear(128, 2 * 58</li>
  </ol>
  <p>To train my model, I
    used MSELoss and the Adam optimizer with
    </code><code>learning_rate=3e-4</code> and with <code>num_epochs = 20</code>.</p>
  </p>
  <h4>Here are the results:</h4>
  <div class="row">
    <div class="column">Success Cases</div>
    <div class="column">
      <img src="output/p1_s1.png" alt="Success 1" />
    </div>
    <div class="column">
      <img src="output/p1_s2.png" alt="Success 2" />
    </div>
    <div class="column">
      <img src="output/p1_s3.png" alt="Success 3" />
    </div>
  </div>
  <div class="row">
    <div class="column">Failure Cases</div>
    <div class="column">
      <img src="output/p1_f1.png" alt="Fail 1" />
    </div>
    <div class="column">
      <img src="output/p1_f2.png" alt="Fail 2" />
    </div>
    <div class="column">
      <img src="output/p1_f3.png" alt="Fail 3" />
    </div>
  </div>
  <p>Some reasons why these images failed could be because of the nose is generally around the center of an image. The
    model is not good at detecting the
    nose when it is not the case -- when the person's head is rotated, and especially for the case when the person is
    not standing at the middle and his head is very rotated.</p>
  <h4>Training and Validation Accuracy</h4>
  <div class="column">
    <img class="plot" src="output/p1_loss.png" alt="Part 1 Accuracy" />
  </div>


  <h3>Part 2: Full Facial Keypoints Detection</h3>
  <h4>Dataset and Dataloader</h4>
  <p>
    Now we have succeeded in detecting one point, we can do that for more keypoints - 58 keypoints to be exact. Again,
    we are using the <a href=http://www2.imm.dtu.dk/~aam/datasets/datasets.html>IMM Face Dataset</a>.<br>All the
    images
    are resized to 240 x 320. For training, data augmentation is done by randomly rotating the images (at most 12
    degrees).
  </p>
  <p>For the dataloader, I used <code>batch_size = 64</code>.</p>
  <p>Here are some sampled images and the ground-truth face keypoint:</p>
  <div class="row">
    <div class="column_4">
      <img src="output/p2_d1.png" alt="Sample 1" />
    </div>
    <div class="column_4">
      <img src="output/p2_d2.png" alt="Sample 2" />
    </div>
    <div class="column_4">
      <img src="output/p2_d3.png" alt="Sample 3" />
    </div>
  </div>
  <h4>CNN Model</h4>
  <p> I used a neural network with 3 convolution layers, each followed by ReLU and max pooling. I used
    <code>kernel_size = (3, 3)</code> for all the layers that needed one.</p>
  <ol>
    <li>C1 = Conv2d(1, 18, 3)</li>
    <li>C2 = Conv2d(18, 24, 3</li>
    <li>C3 = Conv2d(24, 30, 3)</li>
    <li>C4 = Conv2d(30, 30, 3)</li>
    <li>C5 = Conv2d(30, 25, 3)</li>
    <li>FC1 = Linear(25 * 21 * 30, 128)</li>
    <li>FC2 = Linear(128, 2 * 58</li>
  </ol>
  <p>Similarly to Part 1, I trained my model using
    MSELoss and the Adam optimizer with
    </code><code>learning_rate = 15e-5</code> and with <code>num_epochs = 50</code>.</p>
  </p>
  <h4>Here are the results:</h4>
  <div class="row">
    <div class="column_5">Success Cases</div>
    <div class="column">
      <img src="output/p2_s1.png" alt="Success 1" />
    </div>
    <div class="column">
      <img src="output/p2_s2.png" alt="Success 2" />
    </div>
    <div class="column">
      <img src="output/p2_s3.png" alt="Success 3" />
    </div>
  </div>
  <div class="row">
    <div class="column_5">Failure Cases</div>
    <div class="column">
      <img src="output/p2_f1.png" alt="Fail 1" />
    </div>
    <div class="column">
      <img src="output/p2_f2.png" alt="Fail 2" />
    </div>
    <div class="column">
      <img src="output/p2_f3.png" alt="Fail 3" />
    </div>
  </div>
  <p>Similarly to part 1, the model is not good at detecting rotations of the head. It also fails to detect as
    accuratyly when the person's head it not at the very center of the input image. This problen is improved when I
    lowered the learning rate and increased the number of epochs. Maybe it can be further improved with more data
    augmentation, especially shifting.
  </p>
  <h4>Training and Validation Accuracy</h4>
  <div class="column">
    <img class="plot" src="output/p2_loss.png" alt="Part 2 Accuracy Plot" />
  </div>
  <h4>Learned Filters Visualized</h4>
  <p>Here are the learned filters from the first two layers of my trained CNN model. </p>
  <div class="row">
    <div class="column_5">
      <img src="output/p2_filter1.png" alt="first conv layer filters" />
      <figcaption>first conv layer filters</figcaption>
    </div>
    <div class="column_5">
      <img src="output/p2_filter2.png" alt="second conv layer filters" />
      <figcaption>second conv layer filters</figcaption>
    </div>
  </div>


  <h3>Part 3: Training with a Larger Dataset</h3>
  <h4>Dataset, Dataloader, and CNN Model</h4>
  <p>In this part we will be using a way bigger dataset! (It has 6666 training images and 1008 test images.)</p>
  <p>It would take forever to run if we were to train our model with our laptops. Luckily, we have access to GPUs such
    as Google
    Colab. With <code>batch_size = 512</code>, it took about an hour to run!</p>
  <p>For the CNN, I used <code>ResNet18</code>. And to train, I again used MSELoss and the Adam optimizer with
    <code>learning_rate = 3e-4</code>. But this time I have <code>num_epochs = 100</code>.
  </p>
  <h4>Here are the results:</h4>
  <div class="row">
    <div class="column">
      <img class="part3" src="output/p3_s1.png" alt="Success 1" />
    </div>
    <div class="column">
      <img class="part3" src="output/p3_s2.png" alt="Success 2" />
    </div>
    <div class="column">
      <img class="part3" src="output/p3_s3.png" alt="Success 3" />
    </div>
  </div>
  <div class="row">
    <div class="column">
      <img class="part3" src="output/p3_s4.png" alt="Success 3" />
    </div>
    <div class="column">
      <img class="part3" src="output/p3_s5.png" alt="Success 3" />
    </div>
    <div class="column">
      <img class="part3" src="output/p3_s6.png" alt="Success 3" />
    </div>
  </div>
  <h4>My Collection :)</h4>
  </div>
  <div class="row">
    <div class="column_4">
      <img class="part3_2" src="output/p3_mc1.png" alt="My Collection 1" />
    </div>
    <div class="column_4">
      <img class="part3_2" src="output/p3_mc2.png" alt="My Collection 2" />
    </div>
    <div class="column_4">
      <img class="part3_2" src="output/p3_mc3.png" alt="My Collection 3" />
    </div>
    <div class="column_4">
      <img class="part3_2" src="output/p3_mc4.png" alt="My Collection 3" />
    </div>
  </div>


  <h3>Bells and Whisles</h3>
  <p>Using anti-aliased max pool <code>antialiased_cnns.BlurPool</code> from the <a
      href="https://richzhang.github.io/antialiased-cnns">work of Richard
      Zhang</a> (<a href="https://github.com/adobe/antialiased-cnns">Github</a>) in replace of
    <code>torch.nn.MaxPool2d</code>, I was able to produce better results for part 2. As we can see from the graph, the
    loss drop quicker than before.</p>
  </div>
  <div class="row">
    <div class="column_3">
      <img src="output/p2_loss_blur.png" class="plot" alt="Part 2 Accuracy Plot" />
      <figcaption>Accuracy from before, without anti-aliased cnn.</figcaption>
    </div>
  </div>
  <p>
    I also used the trained model from part 3 to find keypoitns of my face from various years, and created a morphing
    video out of it!<br>
    Here it is: <a href="https://youtu.be/0nH9xbJT-m0">https://youtu.be/0nH9xbJT-m0</a></p>
  <iframe text-align="center" width="420" height="315" src="https://youtu.be/0nH9xbJT-m0">
  </iframe>
</body>

</html>
