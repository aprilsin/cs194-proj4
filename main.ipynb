{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T03:07:20.537743Z",
     "start_time": "2020-11-01T03:07:20.501369Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "assert DATA_DIR.exists()\n",
    "\n",
    "DANES_ROOT = DATA_DIR / Path(\"imm_face_db\")\n",
    "IBUG_ROOT = DATA_DIR / Path(\"ibug_300W_large_face_landmark_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T03:07:18.826799Z",
     "start_time": "2020-11-01T03:07:18.757633Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if not IBUG_ROOT.exists():\n",
    "    !wget https://people.eecs.berkeley.edu/~zhecao/ibug_300W_large_face_landmark_dataset.zip\n",
    "    !unzip 'ibug_300W_large_face_landmark_dataset.zip'    \n",
    "    !rm -r 'ibug_300W_large_face_landmark_dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert DANES_ROOT.exists()\n",
    "assert IBUG_ROOT.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import torch\n",
    "import torchvision.transforms as TT\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cnn\n",
    "from dataloader import NoseKeypointDataset, part1_augment\n",
    "from display import *\n",
    "from learn import test, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T03:08:01.777064Z",
     "start_time": "2020-11-01T03:08:01.723568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialite Datasets\n",
    "\n",
    "# Use all 6 images of the first 32 persons (index 1-32) as the training set\n",
    "# (total 32 x 6 = 192 images)\n",
    "training_set = NoseKeypointDataset(\n",
    "    idxs=np.arange(33), root_dir=DANES_ROOT, transform=part1_augment\n",
    ")\n",
    "assert len(training_set) == 192, len(training_set)\n",
    "\n",
    "# Use images of the remaining 8 persons (index 33-40) as the validation set\n",
    "# (total 8 * 6 = 48 images)\n",
    "validation_set = NoseKeypointDataset(\n",
    "    idxs=np.arange(32, 40), root_dir=DANES_ROOT, transform=part1_augment\n",
    ")\n",
    "assert len(validation_set) == 48\n",
    "\n",
    "# Initialize Dataloaders\n",
    "batch_size = 28\n",
    "train_loader = DataLoader(training_set, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(validation_set, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keypoints(training_set[2][0], training_set[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keypoints(training_set[134][0], training_set[134][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing\n",
    "\n",
    "model = cnn.NoseFinder()\n",
    "epochs = 18\n",
    "learn_rate = 0.002\n",
    "show_every = 1\n",
    "loss_per_epoch = []\n",
    "for ep in range(epochs):\n",
    "    print(f\"========== Start Epoch {ep} ==========\")\n",
    "    trained_model, train_loss = train(\n",
    "        train_loader, model, learn_rate\n",
    "    )\n",
    "    _, valid_loss = test(test_loader, trained_model, show_every)\n",
    "    \n",
    "    print_epoch(ep, train_loss, valid_loss)\n",
    "    loss_per_epoch.append([train_loss, valid_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss progress\n",
    "\n",
    "loss_per_epoch = np.array(loss_per_epoch)\n",
    "show_progress(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T03:09:21.860116Z",
     "start_time": "2020-11-01T03:09:21.818708Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_augment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a2557a66730e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_augment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFaceKeypointsDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_augment'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import torch\n",
    "import torchvision.transforms as TT\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cnn\n",
    "from dataloader import FaceKeypointsDataset\n",
    "from display import *\n",
    "from learn import test, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"imm_face_db\")\n",
    "\n",
    "# Initialite Datasets\n",
    "\n",
    "transform = part2_augment\n",
    "# Use all 6 images of the first 32 persons (index 1-32) as the training set\n",
    "# (total 32 x 6 = 192 images)\n",
    "training_set = FaceKeypointsDataset(\n",
    "    idxs=np.arange(33), root_dir=ROOT_DIR, transform=transform\n",
    ")\n",
    "assert len(training_set) == 192\n",
    "\n",
    "# Use images of the remaining 8 persons (index 33-40) as the validation set\n",
    "# (total 8 * 6 = 48 images)\n",
    "validation_set = FaceKeypointsDataset(\n",
    "    idxs=np.arange(32, 40), root_dir=ROOT_DIR, transform=transform\n",
    ")\n",
    "assert len(validation_set) == 48\n",
    "\n",
    "# Initialize Dataloaders\n",
    "batch_size = 25\n",
    "train_loader = DataLoader(training_set, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(validation_set, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a few input images and their face keypoints.\n",
    "\n",
    "sample = training_set[3]\n",
    "image, points = sample\n",
    "show_keypoints(image, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Start Epoch 0 ==========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ed6a70bca3e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"========== Start Epoch {ep} ==========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     trained_model, train_loss = train(\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaceFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_every\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Training and Testing\n",
    "\n",
    "model = cnn.FaceFinder()\n",
    "epochs = 1\n",
    "learn_rate = 0.001\n",
    "show_every = 3\n",
    "loss_per_epoch = []\n",
    "for ep in range(epochs):\n",
    "    print(f\"========== Start Epoch {ep} ==========\")\n",
    "    trained_model, train_loss = train(\n",
    "        train_loader, model, learn_rate\n",
    "    )\n",
    "    _, valid_loss = test(test_loader, trained_model, show_every)\n",
    "    \n",
    "    print_epoch(ep, train_loss, valid_loss)\n",
    "    loss_per_epoch.append([train_loss, valid_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-902d89c5a733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/cs194-proj4/display.py\u001b[0m in \u001b[0;36mshow_progress\u001b[0;34m(loss_per_ep)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_per_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss progress\n",
    "\n",
    "loss_per_epoch = np.array(loss_per_epoch)\n",
    "show_progress(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import torch\n",
    "import torchvision.transforms as TT\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cnn\n",
    "from dataloader import LargeDataset\n",
    "from display import *\n",
    "from learn import test, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xml = IBUG_ROOT / Path(\"labels_ibug_300W_train.xml\")\n",
    "test_xml = IBUG_ROOT / Path(\"labels_ibug_300W_test_parsed.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialite Datasets\n",
    "\n",
    "training_set = LargeDataset(xml_file=train_xml)\n",
    "# assert len(training_set) == 192\n",
    "validation_set = LargeDataset(xml_file=test_xml)\n",
    "# assert len(validation_set) == 48\n",
    "\n",
    "# Initialize Dataloaders\n",
    "batch_size = 250\n",
    "train_loader = DataLoader(training_set, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(validation_set, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keypoints(training_set[2][0], training_set[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LargeDataset' object has no attribute 'root_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3012d82cf5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_keypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m134\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m134\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/cs194-proj4/dataloader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0massert_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0massert_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LargeDataset' object has no attribute 'root_dir'"
     ]
    }
   ],
   "source": [
    "show_keypoints(training_set[134][0], training_set[134][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing\n",
    "\n",
    "epochs = 18\n",
    "learn_rate = 0.002\n",
    "show_every = 1\n",
    "loss_per_epoch = []\n",
    "model = cnn.ResNet()\n",
    "for ep in range(epochs):\n",
    "    print(f\"========== Start Epoch {ep} ==========\")\n",
    "    trained_model, train_loss = train(\n",
    "        train_loader, model, learn_rate\n",
    "    )\n",
    "    _, valid_loss = test(test_loader, trained_model, show_every)\n",
    "    \n",
    "    print_epoch(ep, train_loss, valid_loss)\n",
    "    loss_per_epoch.append([train_loss, valid_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss progress\n",
    "\n",
    "loss_per_epoch = np.array(loss_per_epoch)\n",
    "show_progress(loss_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
